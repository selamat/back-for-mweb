# Start Calico

> You are viewing the calico-containers documentation for release v0.22.0.

## Add Calico to an Existing Kubernetes Cluster

This document describes the steps required to install Calico on an existing
Kubernetes cluster.

This document explains an installation of Calico that includes Kubernetes NetworkPolicy support.  Older versions
of Calico include annotation-based policy support.  While this is no longer recommended, the documentation
for annotation-based policy can still be found in [an older release](https://github.com/projectcalico/calico-containers/blob/v0.20.0/docs/cni/kubernetes/AnnotationPolicy.md).

### Requirements
- An existing Kubernetes cluster running Kubernetes >= v1.1.  To use NetworkPolicy, Kubernetes >= v1.3.0 is required.
- An `etcd` cluster accessible by all nodes in the Kubernetes cluster
  - Calico can share the etcd cluster used by Kubernetes, but it's recommended
  that a separate cluster is set up.

### About the Calico Components

There are three components of a Calico / Kubernetes integration.
- The Calico per-node docker container, [`calico/node`](https://hub.docker.com/r/calico/node/)
- The [calico-cni](https://github.com/projectcalico/calico-cni) network plugin binaries.
 - This is the combination of two binary executables and a configuration file.
- When using Kubernetes NetworkPolicy, the Calico policy controller is also required. 

The `calico/node` docker container must be run on the Kubernetes master and each
Kubernetes node in your cluster, as it contains the BGP agent necessary for Calico routing to occur.

The `calico-cni` plugin integrates directly with the Kubernetes `kubelet` process
on each node to discover which pods have been created, and adds them to Calico networking.

The `calico/kube-policy-controller` container runs as a pod on top of Kubernetes and implements
the NetworkPolicy API.  This component requires Kubernetes >= 1.3.0.

## Installing Calico Components
### 1. Run `calico/node` and configure the node.

The Kubernetes master and each Kubernetes node require the `calico/node` container.
Each node must also be recorded in the Calico datastore. Running the container and
storing the required information can be achieved using the `calicoctl` utility.

```
# Download and install `calicoctl`
wget https://github.com/projectcalico/calico-containers/releases/download/v0.22.0/calicoctl
sudo chmod +x calicoctl

# Run the calico/node container
sudo export ETCD_AUTHORITY=<ETCD_IP>:<ETCD_PORT> && ./calicoctl node --log-dir=/var/log/calico/ --ip={server-ip}
```

See the [`calicoctl node` documentation](../../calicoctl/node.md#calicoctl-node)
for more information.

#### Example systemd unit file (calico-node.service)
If you're using systemd as your init system then the following service file can be used.

```shell
[Unit]
Description=calicoctl node
After=docker.service
Requires=docker.service

[Service]
User=root
Environment=ETCD_AUTHORITY=<ETCD_IP>:<ETCD_PORT>
PermissionsStartOnly=true
ExecStartPre=/usr/bin/wget -N -P /opt/bin https://github.com/projectcalico/calico-containers/releases/download/v0.22.0/calicoctl
ExecStartPre=/usr/bin/chmod +x /opt/bin/calicoctl
ExecStart=/opt/bin/calicoctl node --detach=false
Restart=always
RestartSec=10

[Install]
WantedBy=multi-user.target
```

> Replace `<ETCD_IP>:<ETCD_PORT>` with your etcd configuration.

### 2. Download and configure the Calico CNI plugins
The Kubernetes `kubelet` calls out to the `calico` and `calico-ipam` plugins.

Download the binaries and make sure they're executable

```shell
$ wget -N -P /opt/cni/bin https://github.com/projectcalico/calico-cni/releases/download/v1.3.1/calico
$ wget -N -P /opt/cni/bin https://github.com/projectcalico/calico-cni/releases/download/v1.3.1/calico-ipam
$ chmod +x /opt/cni/bin/calico /opt/cni/bin/calico-ipam
```
It's recommended that this is done as part of job that manages the `kubelet` process (see below)

The Calico CNI plugins require a standard CNI config file.  The `policy` section is only required when
deploying the `calico/kube-policy-controller` for NetworkPolicy.

```
mkdir -p /etc/cni/net.d
$ cat >/etc/cni/net.d/10-calico.conf <<EOF
{
    "name": "calico-k8s-network",
    "type": "calico",
    "etcd_authority": "<ETCD_IP>:<ETCD_PORT>",
    "log_level": "info",
    "ipam": {
        "type": "calico-ipam"
    },
    "policy": {
        "type": "k8s",
        "k8s_api_root": "http://10.126.98.3:8080/api/v1/"
    }
}
EOF
```
> Replace `<ETCD_IP>:<ETCD_PORT>` with your etcd configuration.

Ensure that k8s_api_root has already been set in your cni configuration, in case that your applicaiton can not connect to kube-apiserver. The following log shows that **k8s_api_root** not set properly. The default of this item is 10.100.0.1:443

```shell
2016-09-13 20:13:14,556 211615 [kube-system/kubernetes-dashboard-2347791317-2eu0w] ERROR Exception hitting Kubernetes API
Traceback (most recent call last):
  File "calico_cni/policy_drivers.py", line 297, in _get_api_pod
  File "site-packages/requests/sessions.py", line 480, in get
  File "site-packages/requests/sessions.py", line 468, in request
  File "site-packages/requests/sessions.py", line 576, in send
  File "site-packages/requests/adapters.py", line 437, in send
ConnectionError: HTTPSConnectionPool(host='10.100.0.1', port=443): Max retries exceeded with url: /api/v1/namespaces/kube-system/pods/kubernetes-dashboard-2347791317-2eu0w (Caused by NewConnectionError('<requests.packages.urllib3.connection.VerifiedHTTPSConnection object at 0x7f67b2568850>: Failed to establish a new connection: [Errno 110] Connection timed out',))
2016-09-13 20:13:14,557 211615 [kube-system/kubernetes-dashboard-2347791317-2eu0w] ERROR Failed to apply profile to endpoint cali265b8dde79a
2016-09-13 20:13:14,662 211615 [kube-system/kubernetes-dashboard-2347791317-2eu0w] ERROR CNI Error:
{
  "msg": "Error querying Kubernetes API",
  "cniVersion": "0.1.0",
  "code": 100,
  "details": "HTTPSConnectionPool(host='10.100.0.1', port=443): Max retries exceeded with url: /api/v1/namespaces/kube-system/pods/kubernetes-dashboard-2347791317-2eu0w (Caused by NewConnectionError('<requests.packages.urllib3.connection.VerifiedHTTPSConnection object at 0x7f67b2568850>: Failed to establish a new connection: [Errno 110] Connection timed out',))"
}
Traceback (most recent call last):
  File "<string>", line 268, in _add_new_endpoint
  File "calico_cni/policy_drivers.py", line 364, in apply_profile
  File "calico_cni/policy_drivers.py", line 301, in _get_api_pod
ApplyProfileError: Error querying Kubernetes API
E0913 20:13:14.690334  191790 cni.go:201] Error adding network: Error querying Kubernetes API; HTTPSConnectionPool(host='10.100.0.1', port=443): Max retries exceeded with url: /api/v1/namespaces/kube-system/pods/kubernetes-dashboard-2347791317-2eu0w (Caused by NewConnectionError('<requests.packages.urllib3.connection.VerifiedHTTPSConnection object at 0x7f67b2568850>: Failed to establish a new connection: [Errno 110] Connection timed out',))
E0913 20:13:14.690399  191790 cni.go:158] Error while adding to cni network: Error querying Kubernetes API; HTTPSConnectionPool(host='10.100.0.1', port=443): Max retries exceeded with url: /api/v1/namespaces/kube-system/pods/kubernetes-dashboard-2347791317-2eu0w (Caused by NewConnectionError('<requests.packages.urllib3.connection.VerifiedHTTPSConnection object at 0x7f67b2568850>: Failed to establish a new connection: [Errno 110] Connection timed out',))
E0913 20:13:14.690445  191790 docker_manager.go:1978] Failed to setup network for pod "kubernetes-dashboard-2347791317-2eu0w_kube-system(25f468af-79ab-11e6-a9c4-a4dcbe04f534)" using network plugins "cni": Error querying Kubernetes API; HTTPSConnectionPool(host='10.100.0.1', port=443): Max retries exceeded with url: /api/v1/namespaces/kube-system/pods/kubernetes-dashboard-2347791317-2eu0w (Caused by NewConnectionError('<requests.packages.urllib3.connection.VerifiedHTTPSConnection object at 0x7f67b2568850>: Failed to establish a new connection: [Errno 110] Connection timed out',)); Skipping pod
E0913 20:13:14.753441  191790 pod_workers.go:183] Error syncing pod 25f468af-79ab-11e6-a9c4-a4dcbe04f534, skipping: failed to "SetupNetwork" for "kubernetes-dashboard-2347791317-2eu0w_kube-system" with SetupNetworkError: "Failed to setup network for pod \"kubernetes-dashboard-2347791317-2eu0w_kube-system(25f468af-79ab-11e6-a9c4-a4dcbe04f534)\" using network plugins \"cni\": Error querying Kubernetes API; HTTPSConnectionPool(host='10.100.0.1', port=443): Max retries exceeded with url: /api/v1/namespaces/kube-system/pods/kubernetes-dashboard-2347791317-2eu0w (Caused by NewConnectionError('<requests.packages.urllib3.connection.VerifiedHTTPSConnection object at 0x7f67b2568850>: Failed to establish a new connection: [Errno 110] Connection timed out',)); Skipping pod"

``` 

For more information on configuring the Calico CNI plugins, see the [configuration guide](https://github.com/projectcalico/calico-cni/blob/v1.3.1/configuration.md)

If you done all of this, exec `calicoctl status` command, you will get 

```shell
calico-node container is running. Status: Up 2 days
Running felix version 1.4.0

IPv4 BGP status
IP: 10.126.98.3    AS Number: 64511 (inherited)
+----------------+-------------------+-------+------------+-------------+
|  Peer address  |     Peer type     | State |   Since    |     Info    |
+----------------+-------------------+-------+------------+-------------+
| 10.126.128.196 | node-to-node mesh |   up  | 2016-09-13 | Established |
+----------------+-------------------+-------+------------+-------------+

IPv6 BGP status
No IPv6 address configured.
```

run `calicoctl pool show` will show ipv4 address that can use assigned.

```shell
+----------------+-------------------+
|   IPv4 CIDR    |      Options      |
+----------------+-------------------+
| 192.168.0.0/16 | ipip,nat-outgoing |
+----------------+-------------------+
+--------------------------+---------+
|        IPv6 CIDR         | Options |
+--------------------------+---------+
| fd80:24e2:f998:72d6::/64 |         |
+--------------------------+---------+
```
But, if you don't get **ipip,nat-outgoing**, run the following command.

```shell
# delete ipv4 CIDR
$ calicoctl pool remove 192.168.0.0/16

# add new ipv4 CIDR
$ calicoctl pool add 192.168.0.0/16 --nat-outgoing --ipip
```
then check again. Ensure that `calicoctl status` can be run properly on all of your server in cluster.

### 3. Deploy the Calico network policy controller
The `calico/kube-policy-controller` implements the Kubernetes NetworkPolicy API.  It is recommended that you run it as a static pod
on each Kubernetes master.

policy controller机制为监听kubernetes 中pod和namespace的变化，namespace中network policy的配置变化，由policy-agent写入到calico的etcd存储中，然后直接由每个节点上的felix转换为iptables规则。

To install the policy controller:

- Create the calico-system namespace:

```
kubectl create ns calico-system
```

- Place [this manifest](https://raw.githubusercontent.com/projectcalico/k8s-policy/master/examples/policy-controller.yaml) in the kubelet's config
directory (usually `/etc/kubernetes/manifests`)

```yaml
# Create this manifest using kubectl to deploy
# the Calico policy controller on Kubernetes.
apiVersion: v1
kind: ReplicationController
metadata:
  name: calico-policy-controller
  namespace: kube-system
  labels:
    k8s-app: calico-policy
    kubernetes.io/cluster-service: "true"
spec:
  replicas: 1
  selector:
    k8s-app: calico-policy
  template:
    metadata:
      name: calico-policy-controller
      namespace: kube-system
      labels:
        kubernetes.io/cluster-service: "true"
        k8s-app: calico-policy
    spec:
      hostNetwork: true
      containers:
        - name: calico-policy-controller
          image: calico/kube-policy-controller:latest
          env:
            # Configure the policy controller with the location of 
            # your etcd cluster.
            - name: ETCD_ENDPOINTS
              value: "<ETCD_ENDPOINTS>"
            - name: K8S_API
              value: "https://kubernetes.default:443"
            - name: CONFIGURE_ETC_HOSTS
              value: "true"
```

Replace the *ETCD_ENDPOINTS* with *http://10.126.98.3:2379*, *https://kubernetes.default:443* with *http://10.126.98.3:8080*

After a few moments, you should see the policy controller enter `Running` state:

```
$ kubectl get pods --namespace=kube-system
NAME                                     READY     STATUS    RESTARTS   AGE
calico-policy-controller-dyfbo           2/2       Running   0          1m
```

## Configuring Kubernetes
### Configuring the Kubelet
The Kubelet needs to be configured to use the Calico network plugin when starting pods.

The `kubelet` can be configured to use Calico by starting it with the following options
- `--network-plugin=cni`
- `--network-plugin-dir=/etc/cni/net.d`

See the [`kubelet` documentation](http://kubernetes.io/docs/admin/kubelet/)
for more details.

#### Example systemd unit file (kubelet.service)
```
[Unit]
Description=Kubernetes Kubelet
Documentation=https://github.com/kubernetes/kubernetes
After=calico-node.service
Requires=calico-node.service

[Service]
ExecStartPre=/usr/bin/wget -N -P /opt/bin https://storage.googleapis.com/kubernetes-release/release/v1.3.0/bin/linux/amd64/kubelet
ExecStartPre=/usr/bin/chmod +x /opt/bin/kubelet
ExecStartPre=/usr/bin/wget -N -P /opt/cni/bin https://github.com/projectcalico/calico-cni/releases/download/v1.3.1/calico
ExecStartPre=/usr/bin/chmod +x /opt/cni/bin/calico
ExecStartPre=/usr/bin/wget -N -P /opt/cni/bin https://github.com/projectcalico/calico-cni/releases/download/v1.3.1/calico-ipam
ExecStartPre=/usr/bin/chmod +x /opt/cni/bin/calico-ipam
ExecStart=/opt/bin/kubelet \
--address=0.0.0.0 \
--allow-privileged=true \
--cluster-dns=10.100.0.10 \
--cluster-domain=cluster.local \
--config=/etc/kubernetes/manifests \
--hostname-override=$private_ipv4 \
--api-servers=http://<API SERVER IP>:8080 \
--network-plugin-dir=/etc/cni/net.d \
--network-plugin=cni \
--logtostderr=true	\
--allow-privileged=true	\
Restart=always
RestartSec=10

[Install]
WantedBy=multi-user.target
```

This unit file ensures that the `kubelet` binary and the `calico` plugin are present.

Restart kubelet and check the log. Then deploy an nginx to check if the calico can work. Use curl http://{nginx-internal-ip}:80 to test the connection between host to container.

### Configuring the Kube-Proxy
In order to use Calico policy with Kubernetes, the `kube-proxy` component must
be configured to leave the source address of service bound traffic intact.
This feature is first officially supported in Kubernetes v1.1.0 and is the default mode starting
in Kubernetes v1.2.0.

We highly recommend using the latest stable Kubernetes release, but if you're using an older release
there are two ways to enable this behavior.
- Option 1: Start the `kube-proxy` with the `--proxy-mode=iptables` option.
- Option 2: Annotate the Kubernetes Node API object with
`net.experimental.kubernetes.io/proxy-mode` set to `iptables`.

See the [kube-proxy documentation](http://kubernetes.io/docs/admin/kube-proxy/)
for more details.

[![Analytics](https://calico-ga-beacon.appspot.com/UA-52125893-3/calico-containers/docs/cni/kubernetes/KubernetesIntegration.md?pixel)](https://github.com/igrigorik/ga-beacon)

### Relation articles

* [https://github.com/projectcalico/calico-cni/blob/v1.3.1/configuration.md](https://github.com/projectcalico/calico-cni/blob/v1.3.1/configuration.md)
* [https://coreos.com/kubernetes/docs/latest/deploy-master.html#network-configuration](https://coreos.com/kubernetes/docs/latest/deploy-master.html#network-configuration)
* [https://github.com/projectcalico/calico-containers/blob/v0.22.0/docs/cni/kubernetes/KubernetesIntegration.md](https://github.com/projectcalico/calico-containers/blob/v0.22.0/docs/cni/kubernetes/KubernetesIntegration.md)


