# 一次spark任务卡住的异常

## 1. 异常说明

spark提交任务后，前N个Stage运行顺利，到达某一个Stage后，卡住，通过spark界面可以看到，executor运行正常，卡住的Stage的task已经分配至executor，但duration time一直增加，task却不结束，同时log中也无异常报出。

## 2. 解决方案

* 分析没有异常说明程序本身没有问题，框架运行也运行正常，很有可能是因为该stage操作较为复杂，将CPU打满。

* 通过spark监控界面找到task被分配到的机器，并登陆，通过**jps -ml** 打印出具体的java进程和main class信息（具体java命令行工具见java下文档）

* 得到pid之后，使用top -p 观察该process，发现确实CPU占用非常高，说明某项操作将CPU占满，此时task并未失败，而是一直在进行

* 通过**top -Hp {pid}**将该进程内部线程信息打印，获得哪条线程占用CPU高

* 通过**jstack {pid}** 将进程堆栈打印，并将上一轮操作中获取的线程号在jstack文件中查询，定位线程**（获取的线程号为十进制，需将获取的线程id转换为十六进制，再进行对照）**
* 上步完成之后，对照代码，即可


## 3. 具体问题具体分析

上述只是问题可能解决方案的一种，也有可能是其他原因造成task等待，task执行卡住，暂时能想到的可能的原因就是操作过于复杂将CPU打满，或者等某种IO资源（网络或者磁盘都有可能）

