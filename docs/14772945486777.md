# Batch Jobs

A job creates one or more pods and ensures that a specified number of them successfully terminate. As pods successfully complete, the job tracks the successful completions. When a specified number of successful completions is reached, the job itself is complete. Deleting a Job will cleanup the pods it created.
A simple case is to create one Job object in order to reliably run one Pod to completion. The Job object will start a new Pod if the first pod fails or is deleted (for example due to a node hardware failure or a node reboot).
A Job can also be used to run multiple pods in parallel.


## Example

```yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: pi
spec:
  template:
    metadata:
      name: pi
    spec:
      containers:
      - name: pi
        image: perl
        command: ["perl",  "-Mbignum=bpi", "-wle", "print bpi(2000)"]
      restartPolicy: Never
```

Run the following command to check it out.

```shell
$ kubectl describe jobs/pi-with-timeout --namespace=batch
Name:				pi-with-timeout
Namespace:			batch
Image(s):			10.126.98.3:5000/perl
Selector:			controller-uid=c648bb8c-99bd-11e6-bc01-a4dcbe04f534
Parallelism:			1
Completions:			1
Start Time:			Mon, 24 Oct 2016 15:45:03 +0800
Active Deadline Seconds:	100s
Labels:				controller-uid=c648bb8c-99bd-11e6-bc01-a4dcbe04f534
				job-name=pi-with-timeout
Pods Statuses:			0 Running / 1 Succeeded / 0 Failed
No volumes.
No events.

```

## Pod Selector

The .spec.selector field is optional. In almost all cases you should not specify it, but if you have to, see Kubernetes deployment feature.

## Parallel Jobs

There are three main types of jobs:

* Non-parallel Jobs
	* normally only one pod is started, unless the pod fails.
	* job is complete as soon as Pod terminates successfully.
* Parallel Jobs with a fixed completion count:
	* specify a non-zero positive value for .spec.completions
	* the job is complete when there is one successful pod for each value in the range 1 to .spec.completions.
	* not implemented yet: each pod passed a different index in the range 1 to .spec.completions.
* Parallel Jobs with a work queue:
	* do not specify .spec.completions
	* the pods must coordinate with themselves or an external service to determine what each should work on
	* each pod is independently capable of determining whether or not all its peers are done, thus the entire Job is done.
	* when any pod terminates with success, no new pods are created.
	* once at least one pod has terminated with success and all pods are terminated, then the job is completed with success.
	* once any pod has exited with success, no other pod should still be doing any work or writing any output. They should all be in the process of exiting.

For a Non-parallel job, you can leave both .spec.completions and .spec.parallelism unset. When both are unset, both are defaulted to 1.

For a Fixed Completion Count job, you should set .spec.completions to the number of completions needed. You can set .spec.parallelism, or leave it unset and it will default to 1.

For a Work Queue Job, you must leave .spec.completions unset, and set .spec.parallelism to a non-negative integer.

For more information about how to make use of the different types of job, see the job patterns section.


## Handling Pod and Container Failures

A Container in a Pod may fail for a number of reasons, such as because the process in it exited with a non-zero exit code, or the Container was killed for exceeding a memory limit, etc. If this happens, and the .spec.template.containers[].restartPolicy = "OnFailure", then the Pod stays on the node, but the Container is re-run. Therefore, your program needs to handle the case when it is restarted locally, or else specify .spec.template.containers[].restartPolicy = "Never"

## Job Termination and Cleanup

When a Job completes, no more Pods are created, but the Pods are not deleted either. Since they are terminated, they don’t show up with kubectl get pods, but they will show up with kubectl get pods -a. Keeping them around allows you to still view the logs of completed pods to check for errors, warnings, or other diagnostic output. The job object also remains after it is completed so that you can view its status. It is up to the user to delete old jobs after noting their status. Delete the job with kubectl (e.g. kubectl delete jobs/pi or kubectl delete -f ./job.yaml). When you delete the job using kubectl, all the pods it created are deleted too.

If a Job’s pods are failing repeatedly, the Job will keep creating new pods forever, by default. Retrying forever can be a useful pattern. If an external dependency of the Job’s pods is missing (for example an input file on a networked storage volume is not present), then the Job will keep trying Pods, and when you later resolve the external dependency (for example, creating the missing file) the Job will then complete without any further action.

However, if you prefer not to retry forever, you can set a deadline on the job. Do this by setting the spec.activeDeadlineSeconds field of the job to a number of seconds. The job will have status with reason: DeadlineExceeded. No more pods will be created, and existing pods will be deleted.

```yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: pi-with-timeout
spec:
  activeDeadlineSeconds: 100
  template:
    metadata:
      name: pi
    spec:
      containers:
      - name: pi
        image: perl
        command: ["perl",  "-Mbignum=bpi", "-wle", "print bpi(2000)"]
      restartPolicy: Never
```


